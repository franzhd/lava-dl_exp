{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from IPython.display import HTML, display\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dict1, dict2)-> dict:\n",
    "    merged_dict = {}\n",
    "    \n",
    "    for key in dict1.keys():\n",
    "        merged_dict[key] = [dict1[key], dict2[key]]\n",
    "    \n",
    "    return merged_dict\n",
    "\n",
    "\n",
    "def nni_query(tiral_sqlite_path) -> dict:\n",
    "    import sqlite3\n",
    "    import json \n",
    "\n",
    "    table_name = 'MetricData'\n",
    "    # Connect to the SQLite database\n",
    "    connection = sqlite3.connect(tiral_sqlite_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT trialjobId, sequence, data\n",
    "        FROM {table_name}\n",
    "        WHERE trialjobId IN (\n",
    "            SELECT trialjobId\n",
    "            FROM MetricData\n",
    "            WHERE type = 'FINAL'\n",
    "            GROUP BY trialjobId\n",
    "            ORDER BY MAX(data) DESC\n",
    "            LIMIT 5\n",
    "        ) \n",
    "        AND type = 'PERIODICAL'\n",
    "        ORDER BY trialjobId, sequence;\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    score_dict = {}\n",
    "    for row in results:\n",
    "        # print(f\"TrialjobId: {row[0]}, Sequence: {row[1]}, Data: {row[2]}\")\n",
    "        trialjob_id = row[0]\n",
    "        sequence = row[1]\n",
    "        data = float(row[2].strip('\"'))\n",
    "\n",
    "        # If trialjob_id is not already in the dictionary, add it with an empty list\n",
    "        if trialjob_id not in score_dict:\n",
    "            score_dict[trialjob_id] = []\n",
    "\n",
    "        # Append the data to the list, maintaining the order by sequence\n",
    "        score_dict[trialjob_id].append(data)\n",
    "\n",
    "    # for trialjob_id, data_list in score_dict.items():\n",
    "    #     print(f\"TrialjobId: {trialjob_id}, Data: {data_list}\")\n",
    "\n",
    "    query2 = f\"\"\"\n",
    "    SELECT trialjobId, data\n",
    "    FROM TrialJobEvent\n",
    "    WHERE event = 'WAITING'\n",
    "    AND trialjobId IN (SELECT trialjobId\n",
    "        FROM MetricData\n",
    "        WHERE type = 'FINAL'\n",
    "        GROUP BY trialjobId\n",
    "        ORDER BY MAX(data) DESC\n",
    "        LIMIT 5);\n",
    "\"\"\" \n",
    "    cursor.execute(query2)\n",
    "    results2 = cursor.fetchall()\n",
    "    connection.close()\n",
    "    params_dict = {}\n",
    "    for row in results2:\n",
    "                   results = cursor.fetchall()\n",
    "            print(results)\n",
    "            score_dict = {}\n",
    "            for row in results:\n",
    "                trialjob_id = row[0]\n",
    "                sequence = row[1]\n",
    "                print(row[2])\n",
    "\n",
    "            # If trialjob_id is not already in the dictionary, add it with an empty list\n",
    "            if trialjob_id not in score_dict.keys():\n",
    "                score_dict[trialjob_id] = []\n",
    "\n",
    "            # Append the data to the list, maintaining the order by sequence\n",
    "            score_dict[trialjob_id].append(data) #print(f\"TrialjobId: {row[0]}, parameters: {row[1]}\")\n",
    "        trialjob_id = row[0]\n",
    "        parameters = json.loads(row[1])\n",
    "        # If trialjob_id is not already in the dictionary, add it with an empty list\n",
    "        if trialjob_id not in params_dict:\n",
    "        # Append the data to the list, maintaining the order by sequence\n",
    "            params_dict[trialjob_id] = (parameters['parameters'])\n",
    "\n",
    "    for trialjob_id, params in params_dict.items():\n",
    "        print(f\"TrialjobId: {trialjob_id}, Params: {params}\")\n",
    "\n",
    "    return  merge_dicts(params_dict, score_dict)   \n",
    "    # Close the database connection\n",
    "\n",
    "def show_results(path, experiment_code=None):\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "            # Ottieni la lista di tutti i file e le directory nel path\n",
    "            if experiment_code is None:\n",
    "                dir_content = os.listdir(path)\n",
    "            else:\n",
    "                dir_content = [experiment_code]\n",
    "            \n",
    "            # Scansiona tutti gli elementi nel path\n",
    "            for element in dir_content:\n",
    "                print(f'experiment codename {element}')\n",
    "                db_path = os.path.join(path, element,'db/nni.sqlite')\n",
    "                keys = []\n",
    "                if os.path.isfile(db_path):\n",
    "                    experimet_best_dict = nni_query(db_path)\n",
    "                    if len(experimet_best_dict) >0:\n",
    "                        plt.figure(figsize=(15, 10))\n",
    "                        \n",
    "                        values = next(iter(experimet_best_dict.values()))\n",
    "                        header = [['Trials Name'] + list(values[0].keys())]\n",
    "\n",
    "                        for key, value in experimet_best_dict.items():\n",
    "                            plt.plot(range(len(value[1])), value[1], label=f'{key}, best:{max(value[1]):.3f}')\n",
    "                            keys.append(key)\n",
    "                            rows = [key] +list(value[0].values())\n",
    "                            header.append(rows)\n",
    "\n",
    "                        table = tabulate(header, headers='firstrow', tablefmt='grid')\n",
    "                        print(table)\n",
    "                        \n",
    "                        plt.legend()\n",
    "                        plt.show()\n",
    "\n",
    "                        for trial in keys: \n",
    "                            loss_trial_path = os.path.join(path, element,'trials', trial, 'Trained/loss.txt')\n",
    "                            data = np.loadtxt(loss_trial_path, skiprows=1)\n",
    "                            plt.figure(figsize=(15, 10))\n",
    "                            plt.plot(range(len(data[:,0])), data[:,0], label='train')\n",
    "                            plt.plot(range(len(data[:,1])), data[:,1], label='test')\n",
    "                            plt.legend()\n",
    "                            plt.title(f'{trial} loss graph')\n",
    "                            plt.show()\n",
    "                            image_path = os.path.join(path, element,'trials', trial, 'Trained/confusion_matrix.png')\n",
    "                            img = mpimg.imread(image_path)\n",
    "\n",
    "                            # Visualizza l'immagine\n",
    "                            plt.imshow(img)\n",
    "                            plt.show()                        \n",
    "                            gif_path = os.path.join(path, element,'trials', trial, 'gifs')\n",
    "                            gifs_names= os.listdir(gif_path)\n",
    "                            if len(gifs_names) > 0 :\n",
    "                                end_char = '.gif'\n",
    "                                start_char = '_label'\n",
    "\n",
    "                                gif_td = lambda gif: f'<td> <img src=\"{gif}\" alt=\"Drawing\" style=\"height: 300px;\"/> </td>'\n",
    "                                html = '<table>'\n",
    "                                html += '<tr><td align=\"center\"><b>Input</b></td><td><b>Output</b></td></tr>'\n",
    "                                for i in range(5):\n",
    "                                    pattern1 = re.compile(f'^inp{re.escape(str(i))}_.*\\.gif$')\n",
    "                                    pattern2 = re.compile(f'^out{re.escape(str(i))}_.*\\.gif$')\n",
    "                                    pattern3 = re.compile(f'{re.escape(start_char)}(.*?){re.escape(end_char)}')\n",
    "\n",
    "                                    image_name1 =  [file for file in gifs_names if pattern1.match(file)][0]\n",
    "                                    image_name2 =  [file for file in gifs_names if pattern2.match(file)][0]\n",
    "                                    label = pattern3.search(image_name1).group(1)\n",
    "                                    image_path1 = os.path.join(gif_path, image_name1)\n",
    "                                    image_path2 = os.path.join(gif_path, image_name2)\n",
    "                                    \n",
    "                                    html += '<tr>'\n",
    "                                    html += f'<td><b>Label: {label}</b></td>'\n",
    "                                    html += gif_td(image_path1)\n",
    "                                    html += gif_td(image_path2)\n",
    "                                    html += '</tr>'\n",
    "                                html += '</table>'\n",
    "                                display(HTML(html))\n",
    "\n",
    "                else:\n",
    "                    print('no database file found in the experiment gfolder \\n')               \n",
    "    else:           \n",
    "        print(f\"given path is not a directory: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserire qui tutte le variabili richieste per visualizzare gli esperimenti\n",
    "experiment_name = \"dense_alif_1\"\n",
    "experiment_code = 'j40hq217'\n",
    "path = f'{Path.home()}/lava-dl_exp/nni_experiments/{experiment_name}/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(path, experiment_code=experiment_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Any\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_confusion_matrix(predictions, labels):\n",
    "    \n",
    "    num_label = max(labels)\n",
    "    conf_matrix = confusion_matrix(predictions, labels)\n",
    "    # Plot confusion matrix using Seaborn\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=range(num_label),\n",
    "                yticklabels=range(num_label))\n",
    "\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "def custom_operation(matrix):\n",
    "    # Sum the elements along the last dimension\n",
    "    summed_matrix = np.sum(matrix, axis=-1)\n",
    "\n",
    "    # Divide the sum by the number of elements in the second dimension\n",
    "    divided_matrix = summed_matrix / matrix.shape[1]\n",
    "\n",
    "    # Find the maximum value along the second dimension and its index\n",
    "    max_values = np.max(divided_matrix, axis=1)\n",
    "    max_indices = np.argmax(divided_matrix, axis=1)\n",
    "\n",
    "    # Assign the index of the maximum value to the nth element\n",
    "    result = np.concatenate([divided_matrix.flatten(), max_values.flatten()])\n",
    "    result[-matrix.shape[0]:] = max_indices\n",
    "\n",
    "    return max_indices\n",
    "\n",
    "# Example usage:\n",
    "n = 50  # Replace with your desired value for n\n",
    "matrix = np.random.random((n, 7, 40))  # Replace this with your actual matrix\n",
    "labels = np.random.randint(low=0, high=6, size=n)\n",
    "\n",
    "result = custom_operation(matrix)\n",
    "print(labels)\n",
    "print(result)\n",
    "gen_confusion_matrix(result, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
